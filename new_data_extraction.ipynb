{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:28:19.400877Z",
     "start_time": "2025-08-07T14:28:19.397855Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d208151c09e63b46",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "HOME_DIR = os.path.dirname(BASE_DIR)\n",
    "new_data_dates = os.listdir(os.path.join(HOME_DIR, \"hl-node-fills\"))\n",
    "\n",
    "# --- Config/paths ---\n",
    "DATA_DIR = Path(os.path.join(HOME_DIR, \"data\"))\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "WALLETS_CSV = DATA_DIR / \"wallet_db.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f544fa9b-aa1f-40bd-8f48-11a89c0f7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Wallet DB helpers ---\n",
    "def load_wallet_db(csv_path: Path = WALLETS_CSV) -> Tuple[Dict[str, int], int]:\n",
    "    \"\"\"\n",
    "    Load wallets from CSV into a dict {wallet: wallet_id}, return dict and next_id.\n",
    "    If file doesn't exist, start fresh at 1.\n",
    "    \"\"\"\n",
    "    mapping: Dict[str, int] = {}\n",
    "    next_id = 1\n",
    "    if csv_path.exists():\n",
    "        df = pd.read_csv(csv_path, dtype={\"wallet_id\": \"uint32\", \"wallet\": \"string\"})\n",
    "        if not df.empty:\n",
    "            for wid, wal in zip(df[\"wallet_id\"].astype(\"uint32\"), df[\"wallet\"].astype(\"string\")):\n",
    "                mapping[str(wal)] = int(wid)\n",
    "            next_id = int(df[\"wallet_id\"].max()) + 1\n",
    "    else:\n",
    "        csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        pd.DataFrame(columns=[\"wallet_id\", \"wallet\"]).to_csv(csv_path, index=False)\n",
    "    return mapping, next_id\n",
    "\n",
    "def append_wallet(csv_path: Path, wallet: str, wallet_id: int) -> None:\n",
    "    \"\"\"Append a single wallet row to the CSV.\"\"\"\n",
    "    pd.DataFrame([{\"wallet_id\": wallet_id, \"wallet\": wallet}]).to_csv(\n",
    "        csv_path, mode=\"a\", header=False, index=False\n",
    "    )\n",
    "\n",
    "def get_wallet_id(wallet: str, mapping: Dict[str, int], next_id_ref: List[int], csv_path: Path) -> int:\n",
    "    \"\"\"\n",
    "    Return wallet_id for wallet, creating a new id if needed.\n",
    "    next_id_ref is a single-item list to allow in-place increment.\n",
    "    \"\"\"\n",
    "    w = str(wallet)\n",
    "    wid = mapping.get(w)\n",
    "    if wid is not None:\n",
    "        return wid\n",
    "    wid = next_id_ref[0]\n",
    "    mapping[w] = wid\n",
    "    next_id_ref[0] += 1\n",
    "    append_wallet(csv_path, w, wid)\n",
    "    return wid\n",
    "\n",
    "def retrieve_data(file_path: Path, wallet_map: Dict[str, int], next_id_ref: List[int], wallets_csv: Path = WALLETS_CSV) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a newline-delimited JSON file of trades and produce a normalized DataFrame\n",
    "    for later partitioned saving.\n",
    "    Output columns: coin, price, size, time, is_ask, wallet_id\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    with open(file_path) as f:\n",
    "        append = records.append\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            wallet, trade = json.loads(line)\n",
    "            if int(trade.get(\"tid\")) != 0:\n",
    "                wallet_id = get_wallet_id(wallet, wallet_map, next_id_ref, wallets_csv)\n",
    "        \n",
    "                px = trade.get(\"px\")\n",
    "                sz = trade.get(\"sz\")\n",
    "                # skip malformed\n",
    "                if px is None or sz is None:\n",
    "                    continue\n",
    "        \n",
    "                append(\n",
    "                    {\n",
    "                        \"coin\": trade.get(\"coin\"),\n",
    "                        \"price\": float(px),\n",
    "                        \"size\": float(sz),\n",
    "                        \"time\": trade.get(\"time\"),\n",
    "                        \"is_ask\": trade.get(\"side\") == \"A\",\n",
    "                        \"wallet_id\": wallet_id,\n",
    "                        \"tid\": trade.get(\"tid\"),\n",
    "                    }\n",
    "                )\n",
    "    \n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    # Types & cleaning\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\", unit=\"ms\")\n",
    "    df = df.dropna(subset=[\"time\"])\n",
    "    # enforce dtypes\n",
    "    df[\"price\"] = df[\"price\"].astype(\"float32\")\n",
    "    df[\"size\"] = df[\"size\"].astype(\"float32\")\n",
    "    df[\"is_ask\"] = df[\"is_ask\"].astype(\"bool\")\n",
    "    df[\"wallet_id\"] = df[\"wallet_id\"].astype(\"uint32\")\n",
    "    df[\"tid\"] = df[\"tid\"].astype(\"uint32\")\n",
    "    \n",
    "    return df[[\"coin\", \"price\", \"size\", \"time\", \"is_ask\", \"wallet_id\", \"tid\"]]\n",
    "\n",
    "def convert_to_trade_df(df):\n",
    "    df_ask = df[df[\"is_ask\"]].drop(\"is_ask\", axis=1)\n",
    "    df_bid = df[~df[\"is_ask\"]].drop(\"is_ask\", axis=1)\n",
    "    df_trades = pd.merge(\n",
    "        df_ask,\n",
    "        df_bid,\n",
    "        on=[\"coin\", \"price\", \"size\", \"time\", \"tid\"],\n",
    "        how=\"outer\",\n",
    "        validate=\"one_to_one\",\n",
    "        suffixes=(\"_ask\",\"_bid\"),\n",
    "    ).rename(columns={\"wallet_id_ask\":\"seller\", \"wallet_id_bid\":\"buyer\"}).drop(\"tid\", axis=1)\n",
    "    return df_trades\n",
    "\n",
    "def _target_path_for(coin: str, dt: pd.Timestamp) -> Path:\n",
    "    return DATA_DIR / str(coin) / f\"{dt.date()}.parquet\"\n",
    "\n",
    "def _write_daily_parquet(target: Path, df_day: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Write/merge the daily file. If target exists, read, concat, de-dup, sort, write.\n",
    "    We de-dup on [time, wallet_id, price, size, is_ask] as a reasonable row identity.\n",
    "    \"\"\"\n",
    "    target.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Keep only required columns & types\n",
    "    cols = [\"price\", \"size\", \"time\", \"seller\", \"buyer\"]\n",
    "    df_day = df_day[cols].copy()\n",
    "\n",
    "    if target.exists():\n",
    "        try:\n",
    "            old = pd.read_parquet(target, engine=\"pyarrow\")\n",
    "            # Cast to same dtypes to avoid upcasting surprises\n",
    "            old[\"price\"] = old[\"price\"].astype(\"float32\")\n",
    "            old[\"size\"] = old[\"size\"].astype(\"float32\")\n",
    "            old[\"time\"] = pd.to_datetime(old[\"time\"], errors=\"coerce\")\n",
    "            old[\"seller\"] = old[\"seller\"].astype(\"uint64\")\n",
    "            old[\"buyer\"] = old[\"buyer\"].astype(\"uint64\")\n",
    "            df_day = pd.concat([old, df_day], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to read existing parquet {target}: {e}. Overwriting.\")\n",
    "\n",
    "    df_day = df_day.dropna(subset=[\"time\"]).drop_duplicates(\n",
    "        subset=[\"time\", \"seller\", \"buyer\", \"price\", \"size\"], keep=\"last\"\n",
    "    )\n",
    "    df_day = df_day.sort_values(\"time\")\n",
    "    df_day.to_parquet(target, index=False, engine=\"pyarrow\", compression=\"snappy\")\n",
    "\n",
    "def save_partitioned(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Save rows to data/<coin>/<YYYY-MM-DD>.parquet, merging per-day files if present.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        logger.warning(\"No data to save.\")\n",
    "        return\n",
    "\n",
    "    # Add date for grouping\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = df[\"time\"].dt.date\n",
    "\n",
    "    # Group by coin/date\n",
    "    for (coin, day), g in df.groupby([\"coin\", \"date\"], sort=False):\n",
    "        if pd.isna(coin) or coin == \"\":\n",
    "            logger.warning(\"Skipping rows with empty coin.\")\n",
    "            continue\n",
    "        target = DATA_DIR / str(coin) / f\"{day}.parquet\"\n",
    "        _write_daily_parquet(target, g)\n",
    "\n",
    "    logger.info(\"Data has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c5f03ea-a379-44c5-a344-86b91c765624",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-02 13:38:19.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m/home/debian/hl-node-fills/20250617/10.json is processing\u001b[0m\n",
      "\u001b[32m2025-10-02 13:38:22.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_partitioned\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mData has been saved successfully.\u001b[0m\n",
      "\u001b[32m2025-10-02 13:38:22.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m/home/debian/hl-node-fills/20250617/14.json is processing\u001b[0m\n",
      "\u001b[32m2025-10-02 13:38:28.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_partitioned\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mData has been saved successfully.\u001b[0m\n",
      "\u001b[32m2025-10-02 13:38:28.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m/home/debian/hl-node-fills/20250617/12.json is processing\u001b[0m\n",
      "\u001b[32m2025-10-02 13:38:32.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_partitioned\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mData has been saved successfully.\u001b[0m\n",
      "\u001b[32m2025-10-02 13:38:32.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m/home/debian/hl-node-fills/20250617/19.json is processing\u001b[0m\n",
      "\u001b[32m2025-10-02 13:38:40.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_partitioned\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mData has been saved successfully.\u001b[0m\n",
      "\u001b[32m2025-10-02 13:38:40.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m/home/debian/hl-node-fills/20250617/0.json is processing\u001b[0m\n",
      "\u001b[32m2025-10-02 13:38:49.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_partitioned\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mData has been saved successfully.\u001b[0m\n",
      "\u001b[32m2025-10-02 13:38:49.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m/home/debian/hl-node-fills/20250617/4.json is processing\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m file_full_path = os.path.join(HOME_DIR, \u001b[33m\"\u001b[39m\u001b[33mhl-node-fills\u001b[39m\u001b[33m\"\u001b[39m, date, file_name)\n\u001b[32m     13\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_full_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is processing\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df = \u001b[43mretrieve_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_full_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwallet_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_id_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWALLETS_CSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m trade_df = convert_to_trade_df(df)\n\u001b[32m     16\u001b[39m save_partitioned(trade_df)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mretrieve_data\u001b[39m\u001b[34m(file_path, wallet_map, next_id_ref, wallets_csv)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line.strip():\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m wallet, trade = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m wallet_id = get_wallet_id(wallet, wallet_map, next_id_ref, wallets_csv)\n\u001b[32m     56\u001b[39m px = trade.get(\u001b[33m\"\u001b[39m\u001b[33mpx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \n\u001b[32m    351\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "new_data_folders = os.listdir(os.path.join(HOME_DIR, \"hl-node-fills\"))\n",
    "\n",
    "wallet_map, next_id = load_wallet_db()\n",
    "next_id_ref = [next_id]  # mutable holder\n",
    "\n",
    "\n",
    "for i, date in enumerate(new_data_folders):\n",
    "    hour_file_names = os.listdir(os.path.join(HOME_DIR, \"hl-node-fills\", date))\n",
    "\n",
    "    for file_name in hour_file_names:\n",
    "        file_full_path = os.path.join(HOME_DIR, \"hl-node-fills\", date, file_name)\n",
    "\n",
    "        logger.info(f\"{file_full_path} is processing\")\n",
    "        df = retrieve_data(Path(file_full_path), wallet_map, next_id_ref, WALLETS_CSV)\n",
    "        trade_df = convert_to_trade_df(df)\n",
    "        save_partitioned(trade_df)\n",
    "\n",
    "    logger.info(f\"Processed {i} out of {len(new_data_folders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030f901-b94f-4c83-9c18-78009856fc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca28208-3fe4-4a84-8353-30c1f093f9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f9fabc7746c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:28:14.574135Z",
     "start_time": "2025-08-07T14:28:14.570969Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8426136bce776733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:28:14.630828Z",
     "start_time": "2025-08-07T14:28:14.627980Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "new_data_folders = os.listdir(os.path.join(HOME_DIR, \"hl-node-fills\"))\n",
    "\n",
    "wallet_map, next_id = load_wallet_db()\n",
    "next_id_ref = [next_id]  # mutable holder\n",
    "file_full_path = os.path.join(HOME_DIR, \"hl-node-fills\", \"20250716\", \"0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83efbd5b7813f05d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:28:14.734486Z",
     "start_time": "2025-08-07T14:28:14.731614Z"
    }
   },
   "outputs": [],
   "source": [
    "# logger.info(f\"{file_full_path} is processing\")\n",
    "# df = retrieve_data(Path(file_full_path), wallet_map, next_id_ref, WALLETS_CSV)\n",
    "trade_df = convert_to_trade_df(df)\n",
    "# save_partitioned(trade_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de2fa8b7b8fe2ffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:28:14.785636Z",
     "start_time": "2025-08-07T14:28:14.783052Z"
    }
   },
   "outputs": [],
   "source": [
    "dfg = df.groupby([\"coin\", \"price\", \"size\", \"time\", \"tid\"]).size().reset_index(name=\"n_rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68d0efafb9908d12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:28:14.890020Z",
     "start_time": "2025-08-07T14:28:14.887339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coin</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>time</th>\n",
       "      <th>is_ask</th>\n",
       "      <th>wallet_id</th>\n",
       "      <th>tid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [coin, price, size, time, is_ask, wallet_id, tid]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"tid\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2af844e7bc9b3c9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:28:14.942641Z",
     "start_time": "2025-08-07T14:28:14.939568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_df[(trade_df[\"seller\"].isna()) & (trade_df[\"buyer\"].isna())].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d25f00cd37feb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:28:14.994712Z",
     "start_time": "2025-08-07T14:28:14.991613Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e630a176d93e21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:28:15.046308Z",
     "start_time": "2025-08-07T14:28:15.043603Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf3a146d858753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

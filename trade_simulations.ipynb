{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import datetime",
   "id": "bed74684c0bf7842"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T12:35:25.081039804Z",
     "start_time": "2025-12-26T12:35:25.023414495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def df_detected_to_labeled(df_simulated, df_detected):\n",
    "    df_labeled_b_ = pd.merge(\n",
    "        df_simulated,\n",
    "        df_detected[df_detected[\"open_side\"] == \"buy\"],\n",
    "        left_on=[\"time\", \"buyer\"],\n",
    "        right_on=[\"open_time\", \"wallet_id\",],\n",
    "    )\n",
    "    df_labeled__s = pd.merge(\n",
    "        df_simulated,\n",
    "        df_detected[df_detected[\"close_side\"] == \"sell\"],\n",
    "        left_on=[\"time\", \"seller\"],\n",
    "        right_on=[\"close_time\", \"wallet_id\",],\n",
    "    )\n",
    "    df_labeled_s_ = pd.merge(\n",
    "        df_simulated,\n",
    "        df_detected[df_detected[\"open_side\"] == \"sell\"],\n",
    "        left_on=[\"time\", \"seller\"],\n",
    "        right_on=[\"open_time\", \"wallet_id\",],\n",
    "    )\n",
    "    df_labeled__b = pd.merge(\n",
    "        df_simulated,\n",
    "        df_detected[df_detected[\"close_side\"] == \"buy\"],\n",
    "        left_on=[\"time\", \"buyer\"],\n",
    "        right_on=[\"close_time\", \"wallet_id\",]\n",
    "    )\n",
    "\n",
    "    df_labeled = pd.concat([\n",
    "        df_labeled_b_,\n",
    "        df_labeled__s,\n",
    "        df_labeled_s_,\n",
    "        df_labeled__b,\n",
    "    ])\n",
    "\n",
    "    df_labeled = df_labeled[[\"buyer\", \"seller\", \"time\", \"price\", \"size\", \"wash\"]].dropna()\n",
    "    df_labeled = df_labeled.drop_duplicates()\n",
    "\n",
    "\n",
    "    df_matrix_prediction = pd.merge(\n",
    "        df_simulated,\n",
    "        df_labeled,\n",
    "        on=[\"buyer\", \"seller\", \"time\", \"price\", \"size\"],\n",
    "        how=\"outer\"\n",
    "    ).rename({\"wash_x\": \"true_label\", \"wash_y\": \"prediction_label\"}, axis=\"columns\")\n",
    "\n",
    "    df_matrix_prediction.loc[~df_matrix_prediction[\"prediction_label\"].isna(), \"prediction_label\"] = True\n",
    "    df_matrix_prediction.loc[df_matrix_prediction[\"prediction_label\"].isna(), \"prediction_label\"] = False\n",
    "    df_matrix_prediction[\"true_label\"] = (df_matrix_prediction[\"true_label\"] != \"No\")\n",
    "\n",
    "    return df_matrix_prediction\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "def analyze_labels(df):\n",
    "    # Extract columns\n",
    "    y_true = df[\"true_label\"].astype(bool)\n",
    "    y_pred = df[\"prediction_label\"].astype(bool)\n",
    "\n",
    "    # Confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    print(\"=== Confusion Matrix ===\")\n",
    "    print(f\"TP (correct wash detected):      {tp}\")\n",
    "    print(f\"FP (false wash alarms):          {fp}\")\n",
    "    print(f\"FN (missed wash trades):         {fn}\")\n",
    "    print(f\"TN (correct non-wash):           {tn}\")\n",
    "    print()\n",
    "\n",
    "    # Core metrics\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(\"=== Metrics ===\")\n",
    "    print(f\"Accuracy:       {acc:.4f}\")\n",
    "    print(f\"Precision:      {prec:.4f}\")\n",
    "    print(f\"Recall:         {rec:.4f}\")\n",
    "    print(f\"F1 Score:       {f1:.4f}\")\n",
    "    print()\n",
    "\n",
    "    # Rates\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "    print(\"=== Error Rates ===\")\n",
    "    print(f\"False Positive Rate:  {fpr:.4f}\")\n",
    "    print(f\"False Negative Rate:  {fnr:.4f}\")\n",
    "    print()\n",
    "\n",
    "    # Classification report\n",
    "    print(\"=== Classification Report ===\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"No Wash\", \"Wash\"]))\n"
   ],
   "id": "3801a795bc85cf2c",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def simulate_trades(df_original, n_trades=10000, seed=None):\n",
    "    \"\"\"\n",
    "    Simulate a sequence of trades based on statistical patterns learned\n",
    "    from an existing trades dataframe.\n",
    "\n",
    "    Output columns:\n",
    "        buyer (int), seller (int), time, price, size\n",
    "    \"\"\"\n",
    "\n",
    "    # ================================================================\n",
    "    # 0. Preparation\n",
    "    # ================================================================\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    df = df_original.copy()\n",
    "\n",
    "    # Ensure datetime\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "    # ================================================================\n",
    "    # 1. GLOBAL MARKET-LEVEL INTER-TRADE TIME (THIS FIXES YOUR ISSUE)\n",
    "    # ================================================================\n",
    "    market_dt = df['time'].diff().dt.total_seconds().dropna()\n",
    "    market_dt = market_dt[market_dt > 0]   # remove zeros if present\n",
    "\n",
    "    if len(market_dt) == 0:\n",
    "        global_dt_mean = 1.0\n",
    "    else:\n",
    "        global_dt_mean = market_dt.mean()\n",
    "\n",
    "    # empirical sampling (best)\n",
    "    def sample_dt():\n",
    "        return float(np.random.choice(market_dt.values))\n",
    "\n",
    "    # ================================================================\n",
    "    # 2. WALLET-LEVEL ACTIVITY DISTRIBUTION\n",
    "    # ================================================================\n",
    "\n",
    "    sells = df_all_matched[[\"seller\", \"time\", \"price\", \"size\"]].rename(columns={\"seller\": \"wallet_id\"}).copy()\n",
    "    sells[\"is_ask\"] = True\n",
    "    buys = df_all_matched[[\"buyer\", \"time\", \"price\", \"size\"]].rename(columns={\"buyer\": \"wallet_id\"}).copy()\n",
    "    buys[\"is_ask\"] = False\n",
    "    df_all = pd.concat([sells, buys], ignore_index=True)\n",
    "\n",
    "    df_all[\"notional\"] = df_all[\"price\"] * df_all[\"size\"]\n",
    "    df_all = df_all.groupby([\"wallet_id\", \"time\", \"is_ask\"]).agg(size=(\"size\", \"sum\"), notional=(\"notional\", \"sum\")).reset_index()\n",
    "    df_all[\"price\"] = (df_all[\"notional\"] / df_all[\"size\"]).astype(\"float32\")\n",
    "    wallet_stream = df_all.drop(\"notional\", axis=1)\n",
    "\n",
    "    wallet_counts = wallet_stream['wallet_id'].value_counts().sort_index()\n",
    "    wallet_ids = wallet_counts.index.to_numpy()\n",
    "    wallet_prob = (wallet_counts / wallet_counts.sum()).to_numpy()\n",
    "\n",
    "    # Sample wallet according to its historical activity\n",
    "    def sample_wallet():\n",
    "        return int(np.random.choice(wallet_ids, p=wallet_prob))\n",
    "\n",
    "    # Sample buyer and seller, avoid equal wallets\n",
    "    def sample_wallet_pair():\n",
    "        seller = sample_wallet()\n",
    "        buyer = seller\n",
    "        # avoid self-trade\n",
    "        for _ in range(10):\n",
    "            buyer = sample_wallet()\n",
    "            if buyer != seller:\n",
    "                break\n",
    "        return buyer, seller\n",
    "\n",
    "    # ================================================================\n",
    "    # 3. WALLET-LEVEL SIZE STATISTICS\n",
    "    # ================================================================\n",
    "    size_stats = wallet_stream.groupby('wallet_id')['size'].agg(['mean', 'std'])\n",
    "    global_size_mean = wallet_stream['size'].mean()\n",
    "    global_size_std = wallet_stream['size'].std()\n",
    "\n",
    "    def sample_size(wallet_id):\n",
    "        if wallet_id in size_stats.index:\n",
    "            mu = size_stats.loc[wallet_id, 'mean']\n",
    "            sigma = size_stats.loc[wallet_id, 'std']\n",
    "        else:\n",
    "            mu = global_size_mean\n",
    "            sigma = global_size_std\n",
    "\n",
    "        # fallbacks\n",
    "        if not np.isfinite(mu) or mu <= 0:\n",
    "            mu = global_size_mean\n",
    "        if not np.isfinite(sigma) or sigma <= 0:\n",
    "            sigma = global_size_std\n",
    "\n",
    "        # truncated normal > 0\n",
    "        size = np.random.normal(mu, sigma)\n",
    "        for _ in range(10):\n",
    "            if size > 0:\n",
    "                break\n",
    "            size = np.random.normal(mu, sigma)\n",
    "        return float(max(size, 1e-8))\n",
    "\n",
    "    # ================================================================\n",
    "    # 4. PRICE DYNAMICS: RANDOM WALK WITH SIZE-BASED VOL SCALED\n",
    "    # ================================================================\n",
    "    df_sorted = df.sort_values(\"time\")\n",
    "    price_series = df_sorted['price'].values\n",
    "    price_series = price_series[price_series > 0]\n",
    "\n",
    "    if len(price_series) > 1:\n",
    "        log_ret = np.diff(np.log(price_series))\n",
    "        base_sigma = np.std(log_ret)\n",
    "        if not np.isfinite(base_sigma):\n",
    "            base_sigma = 0.001\n",
    "    else:\n",
    "        base_sigma = 0.001\n",
    "\n",
    "    # start price = last historical price\n",
    "    start_price = float(df_sorted['price'].iloc[-1])\n",
    "\n",
    "    def update_price(prev_price, trade_size):\n",
    "        if prev_price <= 0:\n",
    "            prev_price = 1.0\n",
    "\n",
    "        # scale volatility by sqrt(size / mean_size)\n",
    "        if global_size_mean > 0:\n",
    "            scale = (trade_size / global_size_mean) ** 0.5\n",
    "        else:\n",
    "            scale = 1.0\n",
    "\n",
    "        sigma = base_sigma * scale\n",
    "        shock = np.random.normal(0, sigma)\n",
    "        new_price = prev_price * np.exp(shock)\n",
    "\n",
    "        if new_price <= 0 or not np.isfinite(new_price):\n",
    "            new_price = prev_price\n",
    "\n",
    "        return float(new_price)\n",
    "\n",
    "    # ================================================================\n",
    "    # 5. SIMULATION LOOP\n",
    "    # ================================================================\n",
    "    sim_records = []\n",
    "\n",
    "    time_t = df_sorted['time'].iloc[-1]\n",
    "    price_t = start_price\n",
    "\n",
    "    for _ in tqdm(range(n_trades), desc=\"Simulating trades\"):\n",
    "        # 1. time\n",
    "        dt = sample_dt()\n",
    "        time_t = time_t + pd.Timedelta(seconds=dt)\n",
    "\n",
    "        # 2. participants\n",
    "        buyer, seller = sample_wallet_pair()\n",
    "\n",
    "        # 3. size\n",
    "        size = sample_size(seller)\n",
    "\n",
    "        # 4. price\n",
    "        price_t = update_price(price_t, size)\n",
    "\n",
    "        sim_records.append({\n",
    "            'buyer': buyer,\n",
    "            'seller': seller,\n",
    "            'time': time_t,\n",
    "            'price': price_t,\n",
    "            'size': size\n",
    "        })\n",
    "\n",
    "    df_sim = pd.DataFrame(sim_records)\n",
    "    return df_sim\n"
   ],
   "id": "dd1b2180c3e7d0eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.data_handler import CoinDataStore\n",
    "\n",
    "store = CoinDataStore(\"AVAX\", engine=\"fastparquet\")\n",
    "df_all_matched = store.load_all()\n",
    "df_all_matched"
   ],
   "id": "c253ffdc3e93fc52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_simulated = simulate_trades(df_all_matched, n_trades=1100000, seed=71)",
   "id": "85de74c1f5b751a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_simulated[\"wash\"] = \"No\"",
   "id": "1503fae0b48414f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Market-wide volume comparison\n",
    "# -----------------------------------------------------\n",
    "def compare_total_volume(df_original, df_sim, bin_size='1H'):\n",
    "    \"\"\"\n",
    "    Plot total volume per time bin for original and simulated trades.\n",
    "    \"\"\"\n",
    "    df1 = df_original.copy()\n",
    "    df2 = df_sim.copy()\n",
    "\n",
    "    df1['time'] = pd.to_datetime(df1['time'])\n",
    "    df2['time'] = pd.to_datetime(df2['time'])\n",
    "\n",
    "    # Aggregate sizes per bin\n",
    "    vol_orig = df1.resample(bin_size, on='time')['size'].sum()\n",
    "    vol_sim  = df2.resample(bin_size, on='time')['size'].sum()\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(vol_orig.index, vol_orig.values, label='Original Volume', linewidth=2)\n",
    "    plt.plot(vol_sim.index,  vol_sim.values,  label='Simulated Volume', linewidth=2)\n",
    "\n",
    "    plt.title(f\"Total Market Volume per {bin_size}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Volume\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "e513465729798c49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_total_volume(df_all_matched, df_simulated)",
   "id": "b76df5112aca84e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -----------------------------------------------------\n",
    "# 2. Wallet-specific volume comparison\n",
    "# -----------------------------------------------------\n",
    "def compare_wallet_volume(df_original, df_sim, wallet_id, bin_size='1H'):\n",
    "    \"\"\"\n",
    "    Plot volume per time bin for a specific wallet (buyer OR seller).\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract wallet participation\n",
    "    def extract_wallet(df):\n",
    "        return df[(df['buyer'] == wallet_id) | (df['seller'] == wallet_id)]\n",
    "\n",
    "    df1 = extract_wallet(df_original).copy()\n",
    "    df2 = extract_wallet(df_sim).copy()\n",
    "\n",
    "    if len(df1) == 0:\n",
    "        print(\"Wallet not found in original data.\")\n",
    "    if len(df2) == 0:\n",
    "        print(\"Wallet not found in simulated data.\")\n",
    "\n",
    "    df1['time'] = pd.to_datetime(df1['time'])\n",
    "    df2['time'] = pd.to_datetime(df2['time'])\n",
    "\n",
    "    vol_orig = df1.resample(bin_size, on='time')['size'].sum()\n",
    "    vol_sim  = df2.resample(bin_size, on='time')['size'].sum()\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(vol_orig.index, vol_orig.values, label='Original', linewidth=2)\n",
    "    plt.plot(vol_sim.index,  vol_sim.values,  label='Simulated', linewidth=2)\n",
    "\n",
    "    plt.title(f\"Wallet {wallet_id} Volume per {bin_size}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Volume\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "290cddfffb2b4a8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_wallet_volume(df_all_matched, df_simulated, wallet_id=8)",
   "id": "1a39b429020e38de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T12:28:52.760436088Z",
     "start_time": "2025-12-26T12:28:52.700063112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "time_diff_s = 5 * 60 # 1 minute difference\n",
    "price_diff_pct = 0.01\n",
    "size_diff_pct = 0.01"
   ],
   "id": "60d602ed4ec3cc7c",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T12:29:04.011624170Z",
     "start_time": "2025-12-26T12:28:54.092964100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.simple_wash_detector_utils import detect_wash_trades_local\n",
    "\n",
    "print(f\"number\\t - volume share\\t - count share\")\n",
    "sim_time_detected = detect_wash_trades_local(df_simulated, time_diff_s, price_diff_pct, size_diff_pct, randomization=None, is_final_filtration=False,\n",
    "                                             bin_freq = \"1ns\",\n",
    "                                             round_mode = \"ceil\",)\n",
    "\n",
    "sim_time_detected_share_volume = (sim_time_detected[\"open_size\"] + sim_time_detected[\"close_size\"]).sum() / (df_simulated[\"size\"].sum() * 2)\n",
    "sim_time_detected_share_count = sim_time_detected[\"open_size\"].shape[0] / df_simulated[\"size\"].shape[0]\n",
    "print(f\"{sim_time_detected_share_volume:.{5}f}\\t\\t - {sim_time_detected_share_count:.{5}f}\")"
   ],
   "id": "a530e8b0865fb0fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number\t - volume share\t - count share\n",
      "0.00123\t\t - 0.00251\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T12:35:33.196936709Z",
     "start_time": "2025-12-26T12:35:29.464841132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_matrix_prediction = df_detected_to_labeled(df_simulated, sim_time_detected)\n",
    "analyze_labels(df_matrix_prediction)"
   ],
   "id": "b554b53a1dce2265",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "TP (correct wash detected):      0\n",
      "FP (false wash alarms):          5450\n",
      "FN (missed wash trades):         0\n",
      "TN (correct non-wash):           1094550\n",
      "\n",
      "=== Metrics ===\n",
      "Accuracy:       0.9950\n",
      "Precision:      0.0000\n",
      "Recall:         0.0000\n",
      "F1 Score:       0.0000\n",
      "\n",
      "=== Error Rates ===\n",
      "False Positive Rate:  0.0050\n",
      "False Negative Rate:  0.0000\n",
      "\n",
      "=== Classification Report ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asevlad/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/asevlad/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Wash       1.00      1.00      1.00   1100000\n",
      "        Wash       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00   1100000\n",
      "   macro avg       0.50      0.50      0.50   1100000\n",
      "weighted avg       1.00      1.00      1.00   1100000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asevlad/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a8156335799a44e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Naive Bot Wash",
   "id": "9bb249feade88af3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T12:45:28.873572048Z",
     "start_time": "2025-12-26T12:45:28.817753309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def inject_wash_trades(df,\n",
    "                        n_wash_wallets=5,\n",
    "                        volume_pct=0.05,\n",
    "                        count_pct=0.05,\n",
    "                        wash_delay_seconds=10,\n",
    "                        seed=None):\n",
    "    \"\"\"\n",
    "    Inject naive wash-trading patterns:\n",
    "    A wash-wallet buys from a random wallet, then 10 seconds later sells to another random wallet.\n",
    "\n",
    "    df : original dataframe with columns [buyer, seller, time, price, size]\n",
    "    n_wash_wallets : number of wallets controlled by wash bot\n",
    "    volume_pct : percentage of total volume that should be synthetic wash trades\n",
    "    count_pct  : percentage of total trade count that should be synthetic wash trades\n",
    "    wash_delay_seconds : delay between buy and sell legs\n",
    "\n",
    "    Returns:\n",
    "        df_new with additional:\n",
    "            'is_wash' == 1 for injected wash trades\n",
    "    \"\"\"\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    df = df.sort_values(\"time\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Determine totals from real data\n",
    "    # ----------------------------------------------------------------------\n",
    "    total_vol = df[\"size\"].sum()\n",
    "    total_count = df.shape[0]\n",
    "\n",
    "    target_wash_count  = int(total_count * count_pct)\n",
    "\n",
    "    # Each wash cycle = buy leg + sell leg = 2 trades\n",
    "    n_cycles = max(1, target_wash_count // 2)\n",
    "\n",
    "    # Choose wash-trading wallets (these perform the buy+sell)\n",
    "    unique_wallets = pd.unique(df[\"buyer\"].tolist() + df[\"seller\"].tolist())\n",
    "    wash_wallets = np.random.choice(unique_wallets, size=n_wash_wallets, replace=False)\n",
    "    print(wash_wallets)\n",
    "\n",
    "    # Other wallets (to buy from / sell to)\n",
    "    other_wallets = [w for w in unique_wallets if w not in wash_wallets]\n",
    "    if len(other_wallets) == 0:\n",
    "        raise ValueError(\"Not enough wallets to construct buy-from/sell-to structure.\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Sampling sizes for synthetic wash trades\n",
    "    # ----------------------------------------------------------------------\n",
    "    sizes = df[\"size\"].values\n",
    "    price_series = df.sort_values(\"time\")[\"price\"].values\n",
    "\n",
    "    mean_size, std_size = np.sum(sizes) * volume_pct / n_cycles, np.std(sizes)\n",
    "    if std_size <= 0:\n",
    "        std_size = mean_size * 0.3\n",
    "\n",
    "    # Start timestamps from end of dataset\n",
    "    current_time = df[\"time\"].min() + datetime.timedelta(days=np.random.uniform((df[\"time\"].max() - df[\"time\"].min()).days / 2))\n",
    "\n",
    "    synthetic_records = []\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Generate wash-trading cycles\n",
    "    # ----------------------------------------------------------------------\n",
    "    for _ in tqdm(range(n_cycles), desc=\"Injecting wash trades\"):\n",
    "        # Pick which wash-wallet executes this cycle\n",
    "        ww = int(np.random.choice(wash_wallets))\n",
    "\n",
    "        # Pick random external seller & buyer\n",
    "        seller_ext = int(np.random.choice(other_wallets))\n",
    "        buyer_ext  = int(np.random.choice(other_wallets))\n",
    "\n",
    "        # Ensure they’re different from the wash wallet\n",
    "        while seller_ext == ww:\n",
    "            seller_ext = int(np.random.choice(other_wallets))\n",
    "        while buyer_ext == ww:\n",
    "            buyer_ext = int(np.random.choice(other_wallets))\n",
    "\n",
    "        # Sample trade size\n",
    "        size = max(1e-8, np.random.normal(mean_size, std_size))\n",
    "\n",
    "        # Pick price around last known price\n",
    "        last_price = price_series[-1]\n",
    "        price = last_price * np.exp(np.random.normal(0, 0.002))\n",
    "\n",
    "        # BUY leg\n",
    "        t_buy = current_time + pd.Timedelta(seconds=np.random.randint(1, 60))\n",
    "\n",
    "        synthetic_records.append({\n",
    "            \"buyer\": ww,\n",
    "            \"seller\": seller_ext,\n",
    "            \"time\": t_buy,\n",
    "            \"price\": price,\n",
    "            \"size\": size,\n",
    "            \"wash\": \"Naive\"\n",
    "        })\n",
    "\n",
    "        # SELL leg 10 seconds later\n",
    "        t_sell = t_buy + pd.Timedelta(seconds=wash_delay_seconds)\n",
    "\n",
    "        synthetic_records.append({\n",
    "            \"buyer\": buyer_ext,\n",
    "            \"seller\": ww,\n",
    "            \"time\": t_sell,\n",
    "            \"price\": price,\n",
    "            \"size\": size,\n",
    "            \"wash\": \"Naive\"\n",
    "        })\n",
    "\n",
    "        # Move internal time pointer forward\n",
    "        current_time = t_sell\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Merge and sort\n",
    "    # ----------------------------------------------------------------------\n",
    "    df_new = pd.concat([df, pd.DataFrame(synthetic_records)], ignore_index=True)\n",
    "    df_new = df_new.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "    return df_new"
   ],
   "id": "400afcc50715a6e8",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T12:46:10.994143833Z",
     "start_time": "2025-12-26T12:45:30.302140947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_simulated_wash = inject_wash_trades(\n",
    "    df_simulated,\n",
    "    n_wash_wallets=5,\n",
    "    volume_pct=0.1,\n",
    "    count_pct=0.05,\n",
    "    wash_delay_seconds=10\n",
    ")"
   ],
   "id": "e54b86607ede437",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8564/3100728144.py:41: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unique_wallets = pd.unique(df[\"buyer\"].tolist() + df[\"seller\"].tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 77087  42264  80100 175738  21157]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Injecting wash trades:   0%|          | 0/27500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0e06db8af4a4387a36c48d1983a332b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### No filtration",
   "id": "9b1f081be4f41500"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T12:46:20.701221974Z",
     "start_time": "2025-12-26T12:46:10.995545271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.simple_wash_detector_utils import detect_wash_trades_local\n",
    "\n",
    "print(f\"number\\t - volume share\\t - count share\")\n",
    "sim_time_detected = detect_wash_trades_local(df_simulated_wash, time_diff_s, price_diff_pct, size_diff_pct,\n",
    "                                             randomization=None,\n",
    "                                             bin_freq = \"1ns\",\n",
    "                                             round_mode = \"ceil\",\n",
    "                                             is_final_filtration=False\n",
    "                                             )\n",
    "\n",
    "sim_time_detected_share_volume = (sim_time_detected[\"open_size\"] + sim_time_detected[\"close_size\"]).sum() / df_simulated_wash[\"size\"].sum() / 2\n",
    "sim_time_detected_share_count = sim_time_detected[\"open_size\"].shape[0] / df_simulated_wash.shape[0]\n",
    "print(f\"{sim_time_detected_share_volume:.{5}f}\\t\\t - {sim_time_detected_share_count:.{5}f}\")"
   ],
   "id": "92bc706c1f7d18dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number\t - volume share\t - count share\n",
      "0.08868\t\t - 0.02618\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T12:46:20.753569866Z",
     "start_time": "2025-12-26T12:46:20.704324813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "c50a5d2c1ca0657a",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T12:46:24.520986765Z",
     "start_time": "2025-12-26T12:46:20.755704109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_matrix_prediction = df_detected_to_labeled(df_simulated_wash, sim_time_detected)\n",
    "analyze_labels(df_matrix_prediction)"
   ],
   "id": "6fa333b37afe6bbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "TP (correct wash detected):      54954\n",
      "FP (false wash alarms):          5448\n",
      "FN (missed wash trades):         46\n",
      "TN (correct non-wash):           1094552\n",
      "\n",
      "=== Metrics ===\n",
      "Accuracy:       0.9952\n",
      "Precision:      0.9098\n",
      "Recall:         0.9992\n",
      "F1 Score:       0.9524\n",
      "\n",
      "=== Error Rates ===\n",
      "False Positive Rate:  0.0050\n",
      "False Negative Rate:  0.0008\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Wash       1.00      1.00      1.00   1100000\n",
      "        Wash       0.91      1.00      0.95     55000\n",
      "\n",
      "    accuracy                           1.00   1155000\n",
      "   macro avg       0.95      1.00      0.97   1155000\n",
      "weighted avg       1.00      1.00      1.00   1155000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "abba8b31ab902440"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2fdad3cc51dacc90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "42f306a2a1bb6a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2c96e6271bdcf01b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "79879ae4c55a2b35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cycle Wash bot",
   "id": "f08fe5ae7615db65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def inject_distributed_partner_bot(df,\n",
    "                                   n_wash_wallets=6,\n",
    "                                   volume_pct=0.05,\n",
    "                                   count_pct=0.05,\n",
    "                                   cycle_length=3,\n",
    "                                   wash_gap_seconds=5,\n",
    "                                   seed=None):\n",
    "    \"\"\"\n",
    "    Inject distributed partner wash trading:\n",
    "    Wallets trade in a directed cycle:\n",
    "        w0 -> w1\n",
    "        w1 -> w2\n",
    "        ...\n",
    "        w(k-1) -> w0\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain buyer, seller, time, size, price.\n",
    "    n_wash_wallets : int\n",
    "        Total wallets controlled by wash trader. Must be >= cycle_length.\n",
    "    volume_pct : float\n",
    "        Target wash trading volume / total original volume.\n",
    "    count_pct : float\n",
    "        Target wash trading count / total original count.\n",
    "    cycle_length : int\n",
    "        Size of each cycle group (3–6 recommended).\n",
    "    wash_gap_seconds : int\n",
    "        Averaged time between leg trades inside the cycle.\n",
    "    seed : int or None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_new : DataFrame\n",
    "        With injected wash trades and column is_wash = {0,1}.\n",
    "    \"\"\"\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    df = df.sort_values(\"time\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Determine totals\n",
    "    # ------------------------------------------------------------------\n",
    "    total_vol = df[\"size\"].sum()\n",
    "    total_count = df.shape[0]\n",
    "\n",
    "    target_wash_vol = total_vol * volume_pct\n",
    "    target_wash_count = int(total_count * count_pct)\n",
    "\n",
    "    # Each cycle produces \"cycle_length\" trades\n",
    "    max_cycles = max(1, target_wash_count // cycle_length)\n",
    "\n",
    "    # Pick wash wallets\n",
    "    all_wallets = pd.unique(df[\"buyer\"].tolist() + df[\"seller\"].tolist())\n",
    "    if n_wash_wallets > len(all_wallets):\n",
    "        raise ValueError(\"Not enough wallets in dataset to pick wash wallets.\")\n",
    "\n",
    "    wash_wallets = np.random.choice(all_wallets, size=n_wash_wallets, replace=False)\n",
    "\n",
    "    # Validate cycle length\n",
    "    if cycle_length > len(wash_wallets):\n",
    "        raise ValueError(\"cycle_length cannot exceed n_wash_wallets\")\n",
    "\n",
    "    # Pick a cycle (ordered)\n",
    "    cycle_wallets = list(np.random.choice(wash_wallets, size=cycle_length, replace=False))\n",
    "    print(cycle_wallets)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Sampling distributions\n",
    "    # ------------------------------------------------------------------\n",
    "    mean_size = df[\"size\"].mean()\n",
    "    std_size = df[\"size\"].std()\n",
    "    if not np.isfinite(std_size) or std_size <= 0:\n",
    "        std_size = mean_size * 0.3\n",
    "\n",
    "    last_price = df.sort_values(\"time\")[\"price\"].iloc[-1]\n",
    "\n",
    "    current_time = df[\"time\"].min() + datetime.timedelta(days=np.random.uniform((df[\"time\"].max() - df[\"time\"].min()).days / 2))\n",
    "\n",
    "    synthetic = []\n",
    "    cum_volume = 0.0\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Generate wash cycles\n",
    "    # ------------------------------------------------------------------\n",
    "    for _ in tqdm(range(max_cycles), desc=\"Injecting distributed cycles\"):\n",
    "        # Trade through the cycle:\n",
    "        # (w0 -> w1), (w1 -> w2), ..., (w(k-1) -> w0)\n",
    "\n",
    "        for i in range(cycle_length):\n",
    "            seller = int(cycle_wallets[i])\n",
    "            buyer = int(cycle_wallets[(i + 1) % cycle_length])\n",
    "\n",
    "            # Sample trade size\n",
    "            size = max(0.1, np.random.normal(mean_size, std_size))\n",
    "\n",
    "            # Update cumulative volume\n",
    "            cum_volume += size\n",
    "            if cum_volume >= target_wash_vol:\n",
    "                break\n",
    "\n",
    "            # Sample price around last price\n",
    "            price = last_price * np.exp(np.random.normal(0, 0.002))\n",
    "\n",
    "            # Time increment\n",
    "            dt = np.random.randint(1, wash_gap_seconds)\n",
    "            current_time = current_time + pd.Timedelta(seconds=dt)\n",
    "\n",
    "            synthetic.append({\n",
    "                \"buyer\": buyer,\n",
    "                \"seller\": seller,\n",
    "                \"time\": current_time,\n",
    "                \"price\": price,\n",
    "                \"size\": size,\n",
    "                \"wash\": \"Cycle\"\n",
    "            })\n",
    "\n",
    "        if cum_volume >= target_wash_vol:\n",
    "            break\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Merge and return\n",
    "    # ------------------------------------------------------------------\n",
    "    df_new = pd.concat([df, pd.DataFrame(synthetic)], ignore_index=True)\n",
    "    df_new = df_new.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "    return df_new\n"
   ],
   "id": "20984dd80169027a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_with_cycle_wash = inject_distributed_partner_bot(\n",
    "    df_simulated,\n",
    "    n_wash_wallets=10,      # choose 10 wallets to form wash networks\n",
    "    volume_pct=0.03,        # 10% artificial volume\n",
    "    count_pct=0.01,         # 5% of trades\n",
    "    cycle_length=5,         # 4-wallet loop (A→B→C→D→E→A)\n",
    "    wash_gap_seconds=8\n",
    ")\n",
    "\n",
    "df_with_cycle_wash = inject_distributed_partner_bot(\n",
    "    df_with_cycle_wash,\n",
    "    n_wash_wallets=10,      # choose 10 wallets to form wash networks\n",
    "    volume_pct=0.03,        # 10% artificial volume\n",
    "    count_pct=0.01,         # 5% of trades\n",
    "    cycle_length=4,         # 4-wallet loop (A→B→C→D→A)\n",
    "    wash_gap_seconds=8\n",
    ")\n",
    "\n",
    "df_with_cycle_wash = inject_distributed_partner_bot(\n",
    "    df_with_cycle_wash,\n",
    "    n_wash_wallets=10,      # choose 10 wallets to form wash networks\n",
    "    volume_pct=0.03,        # 10% artificial volume\n",
    "    count_pct=0.01,         # 5% of trades\n",
    "    cycle_length=3,         # 4-wallet loop (A→B→C→A)\n",
    "    wash_gap_seconds=8\n",
    ")\n",
    "\n",
    "df_with_cycle_wash = inject_distributed_partner_bot(\n",
    "    df_with_cycle_wash,\n",
    "    n_wash_wallets=10,      # choose 10 wallets to form wash networks\n",
    "    volume_pct=0.03,        # 10% artificial volume\n",
    "    count_pct=0.01,         # 5% of trades\n",
    "    cycle_length=2,         # 4-wallet loop (A→B→A)\n",
    "    wash_gap_seconds=5\n",
    ")"
   ],
   "id": "760ef784ffb8c617"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### No filtration",
   "id": "72b5eb498d904e7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"volume share\\t - count share\")\n",
    "df_with_cycle_wash[\"time\"] = df_with_cycle_wash[\"time\"].astype(\"datetime64[ms]\")\n",
    "sim_time_detected = detect_wash_trades_local(df_with_cycle_wash, time_diff_s, price_diff_pct, size_diff_pct,\n",
    "                                             randomization=None,\n",
    "                                             bin_freq = \"1ns\",\n",
    "                                             round_mode = \"ceil\",\n",
    "                                             is_final_filtration=False\n",
    "                                             )\n",
    "\n",
    "sim_time_detected_share_volume = (sim_time_detected[\"open_size\"] + sim_time_detected[\"close_size\"]).sum() / (df_simulated[\"size\"].sum() * 2)\n",
    "sim_time_detected_share_count = sim_time_detected[\"open_size\"].shape[0] / df_simulated.shape[0]\n",
    "print(f\"{sim_time_detected_share_volume:.{3}f}\\t\\t - {sim_time_detected_share_count:.{3}f}\")"
   ],
   "id": "117845bede3932d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_matrix_prediction = df_detected_to_labeled(df_with_cycle_wash, sim_time_detected)\n",
    "analyze_labels(df_matrix_prediction)"
   ],
   "id": "fbf13064e8e904dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b967c42afe112ee6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8fe2219915c3df85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b300fdf673a42da7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "431ddcc91a85e3e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "179cb11273e4505"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9352e3ba0273c5de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "99646304a7ffe7f1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
